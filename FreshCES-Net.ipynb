{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d49ca2",
   "metadata": {},
   "source": [
    "#### Installing and loading libraryes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision scikit-learn matplotlib ranger-adabelief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch core\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "\n",
    "# Optimization and scheduling\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "from ranger_adabelief import RangerAdaBelief  # Make sure to install\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02996134",
   "metadata": {},
   "source": [
    "#### Device Configuration and Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a897de",
   "metadata": {},
   "source": [
    "#### Transformations (Data Augmentation and Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ccc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training images\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    # Optional additional augmentations:\n",
    "    # transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet statistics\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/test preprocessing only (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7924cc2",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/path/to/your/images\"  # Update this path\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45faa57e",
   "metadata": {},
   "source": [
    "#### Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceddfcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    " Cross-Validation configuration (80/20)\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset converted to tensors for StratifiedKFold\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Define transformations to resize images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to a tensor\n",
    "])\n",
    "\n",
    "for img, label in dataset:\n",
    "    try:\n",
    "        # Check if img is a file path or already a loaded image object\n",
    "        if isinstance(img, str):  # If it's a file path\n",
    "            with Image.open(img) as im:\n",
    "                # Check image size to avoid DecompressionBombError\n",
    "                if im.size[0] * im.size[1] > 178956970:  # Allowed pixel limit\n",
    "                    continue  # Ignore images that are too large\n",
    "                \n",
    "                # Apply transformation to resize and convert to tensor\n",
    "                im = transform(im)\n",
    "\n",
    "                # If the image is valid, add it to the lists\n",
    "                all_images.append(im)\n",
    "                all_labels.append(label)\n",
    "        else:  # If img is already a loaded image\n",
    "            im = transform(img)  # Apply transformation\n",
    "            all_images.append(im)\n",
    "            all_labels.append(label)\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Capture decompression and other exceptions here\n",
    "        continue  # Ignore images with other errors\n",
    "\n",
    "# Convert images to tensors\n",
    "# No need to use torch.stack, as 'im' is already a tensor due to the transformation\n",
    "\n",
    "all_labels = torch.tensor(all_labels)\n",
    "\n",
    "# Original model\n",
    "weights = ResNet152_Weights.IMAGENET1K_V2  # Optimized weights for ImageNet\n",
    "model = resnet152(weights=weights)\n",
    "\n",
    "# Freeze the first layers\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer1\" in name or \"layer2\" in name:\n",
    "        param.requires_grad = False  # Freeze initial layers (2)\n",
    "\n",
    "# Get features from the final layer\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "# Modify the final layer: add a dense layer and adjust output\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),                      # Regularization with Dropout\n",
    "    nn.Linear(num_features, 128),         # Additional dense layer with 128 units\n",
    "    nn.ReLU(),                            # ReLU activation\n",
    "    nn.Linear(128, len(dataset.classes))  # Output adapted to the number of classes\n",
    ")\n",
    "\n",
    "# Move the model to the device (GPU or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluate optimizer\n",
    "use_ranger = True  # Change to False if you want to use AdamW instead of Ranger\n",
    "if use_ranger:\n",
    "    try:\n",
    "        from ranger_adabelief import RangerAdaBelief\n",
    "        optimizer = RangerAdaBelief(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Ranger optimizer is not installed. Install it with `pip install ranger-adabelief`.\")\n",
    "else:\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Improve the scheduler\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)  # Cosine Annealing Scheduler\n",
    "\n",
    "\n",
    "# Mixup function\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# Freeze initial layers and adjust the rest\n",
    "def freeze_layers(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"layer1\" in name or \"layer2\" in name:\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            param.requires_grad = True\n",
    "\n",
    "freeze_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2ca7e",
   "metadata": {},
   "source": [
    "#### Full Cross-Validated Training Pipeline with Mixup and ResNet-152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        \"\"\"\n",
    "        :param image_paths: List of image file paths or PIL images\n",
    "        :param labels: List of image labels\n",
    "        :param transform: Transformations to apply to the images\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if isinstance(img, str):  # If it's a file path\n",
    "            img = Image.open(img)\n",
    "        elif not isinstance(img, Image.Image):  # If it's neither a path nor a PIL image\n",
    "            raise TypeError(f\"Expected PIL Image or file path, got {type(img)}\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# Define transformations for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet mean and standard deviation\n",
    "])\n",
    "\n",
    "# Cross-Validation configuration\n",
    "k_folds = 5\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Prepare lists of images and labels\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for img, label in dataset:  # This is where you should add your actual dataset\n",
    "    all_images.append(img)\n",
    "    all_labels.append(label)\n",
    "\n",
    "# Create the custom dataset\n",
    "custom_dataset = CustomImageDataset(all_images, all_labels, transform=transform)\n",
    "\n",
    "# Create the DataLoader\n",
    "dataloader = DataLoader(custom_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Cross-Validation results\n",
    "results = []\n",
    "\n",
    "# Iterate over the folds\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(all_images, all_labels)):\n",
    "    print(f\"Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split data into training and validation\n",
    "    train_images, train_labels = [all_images[i] for i in train_idx], [all_labels[i] for i in train_idx]\n",
    "    val_images, val_labels = [all_images[i] for i in val_idx], [all_labels[i] for i in val_idx]\n",
    "\n",
    "    # Create DataLoaders for the current fold\n",
    "    train_dataset = CustomImageDataset(train_images, train_labels, transform=transform)\n",
    "    val_dataset = CustomImageDataset(val_images, val_labels, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Load ResNet152 with pre-trained ImageNet weights\n",
    "    weights = ResNet152_Weights.IMAGENET1K_V2\n",
    "    model = resnet152(weights=weights)\n",
    "\n",
    "    # Freeze the first layers\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"layer1\" in name or \"layer2\" in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Adjust model architecture\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, len(dataset.classes))\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Loss and optimizer configuration\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = RangerAdaBelief(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "    # Cosine Annealing Scheduler\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "\n",
    "    # Mixup function\n",
    "    def mixup_data(x, y, alpha=1.0):\n",
    "        if alpha > 0:\n",
    "            lam = np.random.beta(alpha, alpha)\n",
    "        else:\n",
    "            lam = 1.0\n",
    "        batch_size = x.size()[0]\n",
    "        index = torch.randperm(batch_size).to(x.device)\n",
    "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "        y_a, y_b = y, y[index]\n",
    "        return mixed_x, y_a, y_b, lam\n",
    "\n",
    "    def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "    # Dataset Visualization\n",
    "    dataloader = DataLoader(custom_dataset, batch_size=1, shuffle=True)\n",
    "    examples_per_class = {}\n",
    "    class_labels = dataset.classes\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        for img, label in zip(images, labels):\n",
    "            class_name = class_labels[label.item()]\n",
    "            if class_name not in examples_per_class:\n",
    "                examples_per_class[class_name] = img\n",
    "            if len(examples_per_class) == len(class_labels):\n",
    "                break\n",
    "        if len(examples_per_class) == len(class_labels):\n",
    "            break\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(class_labels), figsize=(15, 5))\n",
    "    for ax, (class_name, img) in zip(axes, examples_per_class.items()):\n",
    "        ax.imshow(img.permute(1, 2, 0))\n",
    "        ax.set_title(class_name)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Training and Validation\n",
    "    epochs = 100\n",
    "    early_stop_patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Apply Mixup\n",
    "            mixed_images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=0.4)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(mixed_images)\n",
    "            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "\n",
    "        # Update the scheduler\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model, f\"/path/to/your/images{fold+1}.pth\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= early_stop_patience:\n",
    "                print(f\"Early stopping triggered for fold {fold+1}.\")\n",
    "                break\n",
    "\n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save fold results\n",
    "    results.append({\n",
    "        'fold': fold+1,\n",
    "        'val_loss': best_val_loss,\n",
    "        'val_accuracy': val_accuracy\n",
    "    })\n",
    "\n",
    "# Print global results\n",
    "print(\"\\nCross-validation results:\")\n",
    "for result in results:\n",
    "    print(f\"Fold {result['fold']}: Val Loss = {result['val_loss']:.4f}, Val Accuracy = {result['val_accuracy']:.2f}%\")\n",
    "\n",
    "mean_loss = np.mean([r['val_loss'] for r in results])\n",
    "mean_accuracy = np.mean([r['val_accuracy'] for r in results])\n",
    "print(f\"Mean Val Loss: {mean_loss:.4f}, Mean Val Accuracy: {mean_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f51e18",
   "metadata": {},
   "source": [
    "#### Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the fold with the best val_loss\n",
    "best_fold = min(results, key=lambda x: x['val_loss'])\n",
    "best_val_loss = best_fold['val_loss']\n",
    "best_fold_index = best_fold['fold']\n",
    "\n",
    "print(f\"The best model is found in fold {best_fold_index} with a val_loss of {best_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Find the fold with the best val_accuracy\n",
    "best_fold_accuracy = max(results, key=lambda x: x['val_accuracy'])\n",
    "best_val_accuracy = best_fold_accuracy['val_accuracy']\n",
    "best_fold_accuracy_index = best_fold_accuracy['fold']\n",
    "\n",
    "print(f\"The best model is found in fold {best_fold_accuracy_index} with a val_accuracy of {best_val_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
